# -*- coding: utf-8 -*-
"""filtering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yk0dFiDaEhrr7Zavm60EqMgoC3TJ4GmF
"""

import sys
import pandas as pd
import sklearn as sk
import string

print(f"Python {sys.version}")
print(f"Pandas {pd.__version__}")
print(f"Scikit-Learn {sk.__version__}")

file1 = open('to.txt', 'r',encoding='utf-8') 
Lines_to = file1.readlines() 
file1 = open('from.txt', 'r',encoding='utf-8') 
Lines_from = file1.readlines()

Lines_to = [line[:-1] for line in Lines_to]
Lines_from = [line[:-1] for line in Lines_from]



import re 
  
def Find(string): 
  
    url = re.findall(r'https?://\S+|www\.\S+', string)        
    return url 
      

def remove_url(data1,data2):
    fr=[]
    to=[]
    for x in range(len(data1)):
        if (len(data1[x])>300) or (len(data1[x])>300):
            continue
        url1=Find(data1[x])
        url2=Find(data2[x])
        if (len(url1)>0) or (len(url2)>0):
            continue
        else:
            fr.append(data1[x])
            to.append(data2[x])
    return fr,to

fro,to=remove_url(Lines_from,Lines_to)

d = {'from':fro,'to':to}
df=pd.DataFrame(d)

import re

def sortclean(text):
    
    text = re.sub(r"i'm", "i am", text)
    text = re.sub(r"we're", "we are", text)
    text = re.sub(r"i'd", "i would", text)
    text = re.sub(r"he's", "he is", text)
    text = re.sub(r"she's", "she is", text)
    text = re.sub(r"it's", "it is", text)
    text = re.sub(r"that's", "that is", text)
    text = re.sub(r"what's", "what is", text)
    text = re.sub(r"where's", "where is", text)
    text = re.sub(r"how's", "how is", text)
    text = re.sub(r"'ll", " will", text)
    text = re.sub(r"'ve", " have", text)
    text = re.sub(r"'re", " are", text)
    text = re.sub(r"[-()#/@;:<>{}`+=~|.!?,]", "", text)

    return text
import string


def remove_URL(text):
    url = re.compile(r'https?://\S+|www\.\S+')
    return url.sub(r'',text)


def remove_html(text):
    html=re.compile(r'<.*?>')
    return html.sub(r'',text)
def remove_emoji(text):
    emoji_pattern = re.compile("["
                           u"\U0001F600-\U0001F64F"  # emoticons
                           u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                           u"\U0001F680-\U0001F6FF"  # transport & map symbols
                           u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                           u"\U00002702-\U000027B0"
                           u"\U000024C2-\U0001F251"
                           "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', text)


def remove_punct(text):
    exclude = set(string.punctuation)
    s = ''.join(ch for ch in text if ch not in exclude)
    return s
def remove_newlinechar(text):
    return text.replace('newlinechar','')
def remove_numbers_out_of_range_data(text):
    new=[]
    for word in text.split(' '):
        if word.isalpha():new.append(word)
    text=' '.join(new)        
    if (len(text.split(' '))>=3) & (len(text.split(' '))<=25):
        return text
    else:
        return None
        

def clean_df(text):
    
    
    text = text.apply(lambda x : x.lower())
        
    text=text.apply(lambda x: sortclean(x))

    text=text.apply(lambda x: remove_emoji(x))
        
    text=text.apply(lambda x : remove_html(x))
    
    text=text.apply(lambda x : remove_punct(x))
    
    text=text.apply(lambda x : remove_newlinechar(x))
    
    text=text.apply(lambda x : remove_numbers_out_of_range_data(x))
    
    text=text.replace('\s+', ' ', regex=True)
    
    return text

df['from']=clean_df(df['from'])
df['to']=clean_df(df['to'])
df.dropna(inplace=True)

df.to_csv('cleaned_data.csv',sep=';')