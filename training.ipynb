{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "016qTdxGYgKx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Bbb5uYI1YgK2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "1ugOjSa4YgK3"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('cleaned_data.csv',sep=';')\n",
    "df.drop('Unnamed: 0',axis=1,inplace = True)\n",
    "df['to']=df['to'].astype(str)\n",
    "df['from']=df['from'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "YYkEoQyuYgK3"
   },
   "outputs": [],
   "source": [
    "df['to']=\"startseq \"+df['to']+' endseq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "lBEFUPx3YgK4"
   },
   "outputs": [],
   "source": [
    "train,test=train_test_split(df,test_size=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "L9jZkEXaYgK4"
   },
   "outputs": [],
   "source": [
    "tokenizer=tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=10000,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' ', char_level=False, oov_token=None,\n",
    "    document_count=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "nDr9vYysYgK4"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train['to'])\n",
    "decoder_input=tokenizer.texts_to_sequences(train['to'])\n",
    "encoder_input=tokenizer.texts_to_sequences(train['from'])\n",
    "decoder_input_test=tokenizer.texts_to_sequences(test['to'])\n",
    "encoder_input_test=tokenizer.texts_to_sequences(test['from'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "LL__cbYOYgK5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "_tFQ9ioMYgK5"
   },
   "outputs": [],
   "source": [
    "encoder_input=pad_sequences(encoder_input,16,padding='post')\n",
    "encoder_input_test=pad_sequences(encoder_input_test,16,padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "IOfEYcyJYgK5"
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "from keras.layers import TimeDistributed\n",
    "import pickle\n",
    "from keras import Input\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRQCqHgJYgK5",
    "outputId": "8fa5e3b2-8706-4efc-e9de-88961c8a0e9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7399259370693783135\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3141979340\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 15760479725377345268\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "0AfYdIY-YgK5"
   },
   "outputs": [],
   "source": [
    "def define_models(n_input, n_output, n_units):\n",
    "    # define training encoder\n",
    "    encoder_inputs = Input(shape=[n_input])\n",
    "    emb=Embedding(n_output,256,input_length=n_input)\n",
    "    encoder_emb=emb(encoder_inputs)\n",
    "    encoder_emb=LSTM(n_units,return_sequences=True)(encoder_emb)\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_emb)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    # define training decoder\n",
    "    decoder_inputs = Input(shape=[n_input])\n",
    "    decoder_emb=emb(decoder_inputs)\n",
    "    decoder_emb=LSTM(n_units,return_sequences=True)(decoder_emb)\n",
    "    decoder_lstm = LSTM(n_units, return_sequences=False, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_emb, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(n_output, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fX8P_YOHYgK6",
    "outputId": "42f71acf-1b1a-409a-bf97-2250ea648cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 16, 256)      2560000     input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_25 (LSTM)                  (None, 16, 128)      197120      embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                  (None, 16, 128)      197120      embedding_7[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                  [(None, 128), (None, 131584      lstm_25[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_28 (LSTM)                  [(None, 128), (None, 131584      lstm_27[0][0]                    \n",
      "                                                                 lstm_26[0][1]                    \n",
      "                                                                 lstm_26[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10000)        1290000     lstm_28[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,507,408\n",
      "Trainable params: 4,507,408\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train_ = define_models(16, 16, 128)\n",
    "adam=keras.optimizers.Adam()\n",
    "train_.compile(optimizer=adam, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "epmhjfZpYgK6"
   },
   "outputs": [],
   "source": [
    "\n",
    "import random \n",
    "def data_generator(output_seq, input_seq, tokenizer, max_length,batch=128):\n",
    "    X1, X2, y = list(), list(), list() \n",
    "    n=0\n",
    "    while 1:\n",
    "        \n",
    "        for key in range(0,len(input_seq)):\n",
    "            key1=input_seq[key]  \n",
    "            # encode the sequence\n",
    "            seq = output_seq[key]\n",
    "            \n",
    "            # split one sequence into multiple X, y pairs\n",
    "            for i in range(len(seq)-1):\n",
    "                if n==batch:\n",
    "                    break\n",
    "                # split into input and output pair\n",
    "                in_seq, out_seq = seq[:i+1], seq[i+1]\n",
    "                if type(in_seq)!= type([]):\n",
    "                    in_seq=list(in_seq)\n",
    "                # encode output sequence\n",
    "                out_seq = to_categorical(out_seq,10000,dtype='float16')\n",
    "                    # store\n",
    "                  \n",
    "                X1.append(key1)\n",
    "                X2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "                n+=1\n",
    "            # yield the batch data\n",
    "                if n==(batch*1):\n",
    "                    ran =random.sample(range(batch), int(batch/10))\n",
    "                    n=0\n",
    "                    yield [array(X1)[ran], pad_sequences(X2, maxlen=16,padding='post')[ran]], array(y)[ran]\n",
    "                    \n",
    "                    X1, X2, y = list(), list(), list()\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "NfMR5s_hYgK6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generator =data_generator(decoder_input, encoder_input, tokenizer, 16,1280)\n",
    "validation_gen=data_generator(decoder_input_test, encoder_input_test, tokenizer, 16,1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_.fit_generator(generator, epochs=10,steps_per_epoch=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "4O2QjsmgYgLA"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq,tokenizer,model):\n",
    "    input_seq=tokenizer.texts_to_sequences([input_seq])\n",
    "    input_seq=pad_sequences(input_seq,16,padding='post')\n",
    "    target_seq=[[1]]\n",
    "    target_seq=pad_sequences(target_seq,16,padding='post')\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = 'startseq'\n",
    "    while not stop_condition:\n",
    "        output_tokens = model.predict([input_seq, target_seq])\n",
    "        sampled_token_index = np.argmax(output_tokens[0,:])\n",
    "        sampled_char = tokenizer.sequences_to_texts([[sampled_token_index]])\n",
    "        decoded_sentence += ' '+ sampled_char[0]\n",
    "\n",
    "        if (sampled_char[0] == 'endseq' or\n",
    "           len(decoded_sentence.split(' ')) > 16):\n",
    "            break\n",
    "        target_seq=tokenizer.texts_to_sequences([decoded_sentence])\n",
    "        target_seq=pad_sequences(target_seq,16,padding='post')\n",
    "\n",
    "    return ' '.join(decoded_sentence.split(' ')[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_.save_weights('weights.h5')\n",
    "symbolic_weights = getattr(train_.optimizer, 'weights')\n",
    "weight_values = keras.backend.batch_get_value(symbolic_weights)\n",
    "with open('optimizer.pkl', 'wb') as f:\n",
    "    pickle.dump(weight_values, f)\n",
    "\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_.load_weights('weights.h5')\n",
    "train_._make_train_function()\n",
    "with open('optimizer.pkl', 'rb') as f:\n",
    "    weight_values = pickle.load(f)\n",
    "train_.optimizer.set_weights(weight_values)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
